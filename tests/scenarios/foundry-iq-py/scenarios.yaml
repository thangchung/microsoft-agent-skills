# Test scenarios for foundry-iq-py skill evaluation
# Each scenario tests a specific usage pattern against acceptance criteria

config:
  model: gpt-4
  max_tokens: 2000
  temperature: 0.3

scenarios:
  # Knowledge Base Retrieval Client
  - name: knowledge_base_retrieval_client
    prompt: |
      Create a KnowledgeBaseRetrievalClient to query a knowledge base.
      Use DefaultAzureCredential and include proper imports.
    expected_patterns:
      - "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient"
      - "DefaultAzureCredential"
      - "knowledge_base_name="
      - "endpoint="
    forbidden_patterns:
      - "from azure.search.documents import KnowledgeBaseRetrievalClient"
    tags:
      - basic
      - retrieval
    mock_response: |
      import os
      from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient
      from azure.identity import DefaultAzureCredential
      
      kb_client = KnowledgeBaseRetrievalClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          knowledge_base_name="my-knowledge-base",
          credential=DefaultAzureCredential()
      )

  # Knowledge Base Query with Citations
  - name: knowledge_base_query_with_citations
    prompt: |
      Query a knowledge base with KnowledgeBaseRetrievalRequest including
      messages, knowledge_source_params with include_references=True.
    expected_patterns:
      - "KnowledgeBaseRetrievalRequest"
      - "KnowledgeBaseMessage"
      - "KnowledgeBaseMessageTextContent"
      - "SearchIndexKnowledgeSourceParams"
      - "include_references=True"
      - "retrieve"
    forbidden_patterns:
      - "include_references=False"
    tags:
      - retrieval
      - citations
    mock_response: |
      import os
      from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient
      from azure.search.documents.knowledgebases.models import (
          KnowledgeBaseRetrievalRequest,
          KnowledgeBaseMessage,
          KnowledgeBaseMessageTextContent,
          SearchIndexKnowledgeSourceParams,
      )
      from azure.identity import DefaultAzureCredential
      
      kb_client = KnowledgeBaseRetrievalClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          knowledge_base_name="my-knowledge-base",
          credential=DefaultAzureCredential()
      )
      
      request = KnowledgeBaseRetrievalRequest(
          messages=[KnowledgeBaseMessage(
              role="user",
              content=[KnowledgeBaseMessageTextContent(text="What is vector search?")]
          )],
          knowledge_source_params=[SearchIndexKnowledgeSourceParams(
              knowledge_source_name="my-knowledge-source",
              include_references=True,
              include_reference_source_data=True
          )],
          include_activity=True
      )
      
      result = kb_client.retrieve(request)
      print(result.response[0].content[0].text)

  # Search Index with Semantic Configuration
  - name: search_index_with_semantic_config
    prompt: |
      Create a SearchIndex with semantic configuration required for agentic retrieval.
      Include vector search with HNSW algorithm and Azure OpenAI vectorizer.
    expected_patterns:
      - "from azure.search.documents.indexes import SearchIndexClient"
      - "SearchIndex"
      - "SemanticSearch"
      - "SemanticConfiguration"
      - "VectorSearch"
      - "HnswAlgorithmConfiguration"
      - "AzureOpenAIVectorizer"
      - "semantic_search="
    forbidden_patterns:
      - "from azure.search.documents.models import SearchIndexClient"
    tags:
      - index
      - semantic
    mock_response: |
      import os
      from azure.search.documents.indexes import SearchIndexClient
      from azure.search.documents.indexes.models import (
          SearchIndex,
          SearchField,
          VectorSearch,
          VectorSearchProfile,
          HnswAlgorithmConfiguration,
          AzureOpenAIVectorizer,
          AzureOpenAIVectorizerParameters,
          SemanticSearch,
          SemanticConfiguration,
          SemanticPrioritizedFields,
          SemanticField,
      )
      from azure.identity import DefaultAzureCredential
      
      credential = DefaultAzureCredential()
      index_client = SearchIndexClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          credential=credential
      )
      
      index = SearchIndex(
          name="my-index",
          fields=[
              SearchField(name="id", type="Edm.String", key=True, filterable=True),
              SearchField(name="content", type="Edm.String", searchable=True),
              SearchField(
                  name="embedding",
                  type="Collection(Edm.Single)",
                  stored=False,
                  vector_search_dimensions=3072,
                  vector_search_profile_name="hnsw-profile"
              ),
          ],
          vector_search=VectorSearch(
              profiles=[VectorSearchProfile(
                  name="hnsw-profile",
                  algorithm_configuration_name="hnsw-algo",
                  vectorizer_name="aoai-vectorizer"
              )],
              algorithms=[HnswAlgorithmConfiguration(name="hnsw-algo")],
              vectorizers=[AzureOpenAIVectorizer(
                  vectorizer_name="aoai-vectorizer",
                  parameters=AzureOpenAIVectorizerParameters(
                      resource_url=os.environ["AZURE_OPENAI_ENDPOINT"],
                      deployment_name="text-embedding-3-large",
                      model_name="text-embedding-3-large"
                  )
              )]
          ),
          semantic_search=SemanticSearch(
              default_configuration_name="semantic-config",
              configurations=[SemanticConfiguration(
                  name="semantic-config",
                  prioritized_fields=SemanticPrioritizedFields(
                      content_fields=[SemanticField(field_name="content")]
                  )
              )]
          )
      )
      
      index_client.create_or_update_index(index)

  # Knowledge Source Creation
  - name: knowledge_source_creation
    prompt: |
      Create a SearchIndexKnowledgeSource with field references
      and add it using create_or_update_knowledge_source.
    expected_patterns:
      - "SearchIndexKnowledgeSource"
      - "SearchIndexKnowledgeSourceParameters"
      - "SearchIndexFieldReference"
      - "source_data_fields"
      - "search_index_name"
      - "create_or_update_knowledge_source"
    forbidden_patterns:
      - "(index_name="
    tags:
      - knowledge-source
    mock_response: |
      import os
      from azure.search.documents.indexes import SearchIndexClient
      from azure.search.documents.indexes.models import (
          SearchIndexKnowledgeSource,
          SearchIndexKnowledgeSourceParameters,
          SearchIndexFieldReference,
      )
      from azure.identity import DefaultAzureCredential
      
      index_client = SearchIndexClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          credential=DefaultAzureCredential()
      )
      
      ks = SearchIndexKnowledgeSource(
          name="my-knowledge-source",
          description="Knowledge source for retrieval",
          search_index_parameters=SearchIndexKnowledgeSourceParameters(
              search_index_name="my-index",
              source_data_fields=[
                  SearchIndexFieldReference(name="id"),
                  SearchIndexFieldReference(name="content"),
              ]
          )
      )
      
      index_client.create_or_update_knowledge_source(knowledge_source=ks)

  # Knowledge Base Creation
  - name: knowledge_base_creation
    prompt: |
      Create a KnowledgeBase with extractive output mode, knowledge sources,
      and Azure OpenAI model configuration.
    expected_patterns:
      - "KnowledgeBase"
      - "KnowledgeBaseAzureOpenAIModel"
      - "KnowledgeSourceReference"
      - "KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA"
      - "KnowledgeRetrievalLowReasoningEffort"
      - "output_mode="
      - "create_or_update_knowledge_base"
    forbidden_patterns:
      - "models=[AzureOpenAIModel("
    tags:
      - knowledge-base
    mock_response: |
      import os
      from azure.search.documents.indexes import SearchIndexClient
      from azure.search.documents.indexes.models import (
          KnowledgeBase,
          KnowledgeBaseAzureOpenAIModel,
          KnowledgeSourceReference,
          AzureOpenAIVectorizerParameters,
          KnowledgeRetrievalOutputMode,
          KnowledgeRetrievalLowReasoningEffort,
      )
      from azure.identity import DefaultAzureCredential
      
      index_client = SearchIndexClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          credential=DefaultAzureCredential()
      )
      
      aoai_params = AzureOpenAIVectorizerParameters(
          resource_url=os.environ["AZURE_OPENAI_ENDPOINT"],
          deployment_name="gpt-4.1-mini",
          model_name="gpt-4.1-mini"
      )
      
      kb = KnowledgeBase(
          name="my-knowledge-base",
          knowledge_sources=[KnowledgeSourceReference(name="my-knowledge-source")],
          models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],
          output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,
          retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort()
      )
      
      index_client.create_or_update_knowledge_base(knowledge_base=kb)

  # MCP Tool Integration
  - name: mcp_tool_agent_integration
    prompt: |
      Create an agent with MCPTool for knowledge base retrieval.
      Use PromptAgentDefinition and include project_connection_id.
    expected_patterns:
      - "from azure.ai.projects.models import MCPTool"
      - "from azure.ai.projects.models import PromptAgentDefinition"
      - "MCPTool"
      - "server_label"
      - "server_url"
      - "project_connection_id"
      - "allowed_tools"
      - "create_version"
    forbidden_patterns:
      - 'allowed_tools=\["retrieve"\]'
    tags:
      - mcp
      - agent
    mock_response: |
      import os
      from azure.ai.projects import AIProjectClient
      from azure.ai.projects.models import MCPTool, PromptAgentDefinition
      from azure.identity import DefaultAzureCredential
      
      client = AIProjectClient(
          endpoint=os.environ["AZURE_AI_PROJECT_ENDPOINT"],
          credential=DefaultAzureCredential()
      )
      
      mcp_endpoint = f"{os.environ['AZURE_SEARCH_ENDPOINT']}/knowledgebases/my-kb/mcp?api-version=2025-11-01-preview"
      
      mcp_tool = MCPTool(
          server_label="knowledge-base",
          server_url=mcp_endpoint,
          require_approval="never",
          allowed_tools=["knowledge_base_retrieve"],
          project_connection_id="my-connection"
      )
      
      with client:
          agent = client.agents.create_version(
              agent_name="rag-agent",
              definition=PromptAgentDefinition(
                  model=os.environ["AZURE_AI_MODEL_DEPLOYMENT_NAME"],
                  instructions="Use the knowledge base to answer questions.",
                  tools=[mcp_tool]
              )
          )
          print(f"Created agent: {agent.id}")
          client.agents.delete_agent(agent.id)

  # Agent Invocation with Tool Choice
  - name: agent_invoke_with_tool_choice
    prompt: |
      Invoke an agent using get_openai_client with tool_choice="required"
      to ensure the knowledge base is always used.
    expected_patterns:
      - "get_openai_client"
      - "conversations.create"
      - "responses.create"
      - 'tool_choice="required"'
      - "extra_body"
      - '"type": "agent_reference"'
    forbidden_patterns:
      - 'tool_choice="auto"'
    tags:
      - agent
      - invocation
    mock_response: |
      import os
      from azure.ai.projects import AIProjectClient
      from azure.identity import DefaultAzureCredential
      
      client = AIProjectClient(
          endpoint=os.environ["AZURE_AI_PROJECT_ENDPOINT"],
          credential=DefaultAzureCredential()
      )
      
      with client:
          openai_client = client.get_openai_client()
          conversation = openai_client.conversations.create()
          
          response = openai_client.responses.create(
              conversation=conversation.id,
              tool_choice="required",
              input="What are the key findings?",
              extra_body={"agent": {"name": "rag-agent", "type": "agent_reference"}}
          )
          
          print(response.output_text)

  # Async Knowledge Base Retrieval
  - name: async_knowledge_base_retrieval
    prompt: |
      Create an async KnowledgeBaseRetrievalClient using azure.search.documents.knowledgebases.aio
      with async context manager and await.
    expected_patterns:
      - "from azure.search.documents.knowledgebases.aio import KnowledgeBaseRetrievalClient"
      - "from azure.identity.aio import DefaultAzureCredential"
      - "async with"
      - "await kb_client.retrieve"
    forbidden_patterns:
      - "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient"
    tags:
      - async
      - retrieval
    mock_response: |
      import os
      import asyncio
      from azure.search.documents.knowledgebases.aio import KnowledgeBaseRetrievalClient
      from azure.search.documents.knowledgebases.models import (
          KnowledgeBaseRetrievalRequest,
          KnowledgeBaseMessage,
          KnowledgeBaseMessageTextContent,
          SearchIndexKnowledgeSourceParams,
      )
      from azure.identity.aio import DefaultAzureCredential
      
      async def main():
          async with KnowledgeBaseRetrievalClient(
              endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
              knowledge_base_name="my-knowledge-base",
              credential=DefaultAzureCredential()
          ) as kb_client:
              request = KnowledgeBaseRetrievalRequest(
                  messages=[KnowledgeBaseMessage(
                      role="user",
                      content=[KnowledgeBaseMessageTextContent(text="What is vector search?")]
                  )],
                  knowledge_source_params=[SearchIndexKnowledgeSourceParams(
                      knowledge_source_name="my-knowledge-source",
                      include_references=True,
                      include_reference_source_data=True
                  )]
              )
              
              result = await kb_client.retrieve(request)
              print(result.response[0].content[0].text)
      
      asyncio.run(main())

  # Hybrid Search Query
  - name: hybrid_search_with_semantic_reranking
    prompt: |
      Perform a hybrid search with semantic reranking using SearchClient.
      Include VectorizedQuery and query_type="semantic".
    expected_patterns:
      - "SearchClient"
      - "VectorizedQuery"
      - "search_text"
      - "vector_queries"
      - 'query_type="semantic"'
      - "semantic_configuration_name"
    forbidden_patterns: []
    tags:
      - search
      - hybrid
    mock_response: |
      import os
      from azure.search.documents import SearchClient
      from azure.search.documents.models import VectorizedQuery
      from azure.identity import DefaultAzureCredential
      
      search_client = SearchClient(
          endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
          index_name="my-index",
          credential=DefaultAzureCredential()
      )
      
      embedding_vector = [0.1] * 3072  # Example embedding
      
      results = search_client.search(
          search_text="vector search benefits",
          vector_queries=[
              VectorizedQuery(
                  vector=embedding_vector,
                  k_nearest_neighbors=50,
                  fields="embedding"
              )
          ],
          select=["id", "content"],
          query_type="semantic",
          semantic_configuration_name="semantic-config",
      )
      
      for result in results:
          print(f"Score: {result['@search.score']}")
          print(f"Content: {result['content']}")

  # Project Connection Creation
  - name: project_connection_creation
    prompt: |
      Create a project connection for the MCP endpoint using requests API
      with bearer token from get_bearer_token_provider.
    expected_patterns:
      - "get_bearer_token_provider"
      - "requests.put"
      - "Bearer"
      - "ProjectManagedIdentity"
      - "RemoteTool"
      - "raise_for_status"
    forbidden_patterns:
      - "api_key"
    tags:
      - connection
      - authentication
    mock_response: |
      import os
      import requests
      from azure.identity import DefaultAzureCredential, get_bearer_token_provider
      
      credential = DefaultAzureCredential()
      bearer_token = get_bearer_token_provider(credential, "https://management.azure.com/.default")()
      
      project_resource_id = os.environ["AZURE_AI_PROJECT_RESOURCE_ID"]
      connection_name = "kb-connection"
      mcp_endpoint = f"{os.environ['AZURE_SEARCH_ENDPOINT']}/knowledgebases/my-kb/mcp?api-version=2025-11-01-preview"
      
      response = requests.put(
          f"https://management.azure.com{project_resource_id}/connections/{connection_name}?api-version=2025-10-01-preview",
          headers={"Authorization": f"Bearer {bearer_token}"},
          json={
              "name": connection_name,
              "type": "Microsoft.MachineLearningServices/workspaces/connections",
              "properties": {
                  "authType": "ProjectManagedIdentity",
                  "category": "RemoteTool",
                  "target": mcp_endpoint,
                  "isSharedToAll": True,
                  "audience": "https://search.azure.com/",
                  "metadata": {"ApiType": "Azure"}
              }
          }
      )
      response.raise_for_status()
      print(f"Connection created: {connection_name}")
