# yaml-language-server: $schema=https://json.schemastore.org/any.json
# Test scenarios for azure-ai-vision-imageanalysis-java skill evaluation

config:
  model: gpt-4
  max_tokens: 2000
  temperature: 0.3

scenarios:
  - name: client_creation
    prompt: |
      Create Java code to set up the Azure AI Vision Image Analysis client
      using KeyCredential authentication.
    expected_patterns:
      - "ImageAnalysisClientBuilder"
      - "KeyCredential"
      - "buildClient"
      - 'System\.getenv\('
    forbidden_patterns:
      - 'endpoint\("https://'
      - 'KeyCredential\("'
    tags:
      - basic
      - authentication
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.core.credential.KeyCredential;

      public class ClientSetup {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              System.out.println("Client initialized successfully");
          }
      }

  - name: generate_caption
    prompt: |
      Create a Java example that generates a caption for an image file
      using Azure AI Vision. Use gender-neutral caption option.
    expected_patterns:
      - "analyze"
      - "VisualFeatures.CAPTION"
      - "BinaryData"
      - "getCaption"
      - "getText"
      - "setGenderNeutralCaption"
    tags:
      - caption
      - basic
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.ai.vision.imageanalysis.models.*;
      import com.azure.core.credential.KeyCredential;
      import com.azure.core.util.BinaryData;
      import java.io.File;
      import java.util.Arrays;

      public class CaptionGeneration {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              BinaryData imageData = BinaryData.fromFile(new File("image.jpg").toPath());
              
              ImageAnalysisResult result = client.analyze(
                  imageData,
                  Arrays.asList(VisualFeatures.CAPTION),
                  new ImageAnalysisOptions().setGenderNeutralCaption(true));
              
              System.out.printf("Caption: \"%s\" (confidence: %.4f)%n",
                  result.getCaption().getText(),
                  result.getCaption().getConfidence());
          }
      }

  - name: extract_text_ocr
    prompt: |
      Create a Java example that extracts text from an image using OCR
      with the READ visual feature. Print each line and word with confidence.
    expected_patterns:
      - "VisualFeatures.READ"
      - "getRead"
      - "getBlocks"
      - "getLines"
      - "getWords"
      - "getText"
      - "getConfidence"
    tags:
      - ocr
      - text-extraction
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.ai.vision.imageanalysis.models.*;
      import com.azure.core.credential.KeyCredential;
      import com.azure.core.util.BinaryData;
      import java.io.File;
      import java.util.Arrays;

      public class TextExtraction {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              BinaryData imageData = BinaryData.fromFile(new File("document.jpg").toPath());
              
              ImageAnalysisResult result = client.analyze(
                  imageData,
                  Arrays.asList(VisualFeatures.READ),
                  null);
              
              for (DetectedTextBlock block : result.getRead().getBlocks()) {
                  for (DetectedTextLine line : block.getLines()) {
                      System.out.printf("Line: '%s'%n", line.getText());
                      for (DetectedTextWord word : line.getWords()) {
                          System.out.printf("  Word: '%s' (confidence: %.4f)%n",
                              word.getText(),
                              word.getConfidence());
                      }
                  }
              }
          }
      }

  - name: detect_objects
    prompt: |
      Create a Java example that detects objects in an image from a URL
      and prints their names and bounding boxes.
    expected_patterns:
      - "analyzeFromUrl"
      - "VisualFeatures.OBJECTS"
      - "getObjects"
      - "getTags"
      - "getBoundingBox"
    tags:
      - object-detection
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.ai.vision.imageanalysis.models.*;
      import com.azure.core.credential.KeyCredential;
      import java.util.Arrays;

      public class ObjectDetection {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              String imageUrl = System.getenv("IMAGE_URL");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              ImageAnalysisResult result = client.analyzeFromUrl(
                  imageUrl,
                  Arrays.asList(VisualFeatures.OBJECTS),
                  null);
              
              for (DetectedObject obj : result.getObjects()) {
                  System.out.printf("Object: %s (confidence: %.4f)%n",
                      obj.getTags().get(0).getName(),
                      obj.getTags().get(0).getConfidence());
                  ImageBoundingBox box = obj.getBoundingBox();
                  System.out.printf("  Location: x=%d, y=%d, w=%d, h=%d%n",
                      box.getX(), box.getY(), box.getWidth(), box.getHeight());
              }
          }
      }

  - name: multiple_features
    prompt: |
      Create a Java example that analyzes an image with multiple visual features:
      caption, tags, objects, and OCR. Use gender-neutral captions.
    expected_patterns:
      - "VisualFeatures.CAPTION"
      - "VisualFeatures.TAGS"
      - "VisualFeatures.OBJECTS"
      - "VisualFeatures.READ"
      - "setGenderNeutralCaption"
      - "getCaption"
      - "getTags"
      - "getObjects"
    tags:
      - advanced
      - multiple-features
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.ai.vision.imageanalysis.models.*;
      import com.azure.core.credential.KeyCredential;
      import java.util.Arrays;

      public class MultiFeatureAnalysis {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              String imageUrl = System.getenv("IMAGE_URL");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              ImageAnalysisResult result = client.analyzeFromUrl(
                  imageUrl,
                  Arrays.asList(
                      VisualFeatures.CAPTION,
                      VisualFeatures.TAGS,
                      VisualFeatures.OBJECTS,
                      VisualFeatures.READ),
                  new ImageAnalysisOptions()
                      .setGenderNeutralCaption(true)
                      .setLanguage("en"));
              
              System.out.println("Caption: " + result.getCaption().getText());
              System.out.println("Tags: " + result.getTags().size());
              System.out.println("Objects: " + result.getObjects().size());
              System.out.println("Text blocks: " + result.getRead().getBlocks().size());
          }
      }

  - name: error_handling
    prompt: |
      Create a Java example showing proper error handling for image analysis
      operations with HttpResponseException handling.
    expected_patterns:
      - "HttpResponseException"
      - "try"
      - "catch"
      - "getResponse().getStatusCode()"
    tags:
      - error-handling
    mock_response: |
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClient;
      import com.azure.ai.vision.imageanalysis.ImageAnalysisClientBuilder;
      import com.azure.ai.vision.imageanalysis.models.VisualFeatures;
      import com.azure.core.credential.KeyCredential;
      import com.azure.core.exception.HttpResponseException;
      import java.util.Arrays;

      public class ErrorHandling {
          public static void main(String[] args) {
              String endpoint = System.getenv("VISION_ENDPOINT");
              String key = System.getenv("VISION_KEY");
              
              ImageAnalysisClient client = new ImageAnalysisClientBuilder()
                  .endpoint(endpoint)
                  .credential(new KeyCredential(key))
                  .buildClient();
              
              try {
                  client.analyzeFromUrl("invalid-url", Arrays.asList(VisualFeatures.CAPTION), null);
              } catch (HttpResponseException e) {
                  System.err.println("Status: " + e.getResponse().getStatusCode());
                  System.err.println("Error: " + e.getMessage());
              }
          }
      }
